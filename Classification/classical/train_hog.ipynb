{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "import joblib\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "# import best model for training\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import cv2 as cv\n",
    "\n",
    "# Show the figures / plots inside the notebook\n",
    "from skimage.color import rgb2gray,rgb2hsv, rgba2rgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.util import random_noise\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.filters import sobel_h, sobel, sobel_v,roberts, gaussian\n",
    "#from skimage.feature import hog\n",
    "from skimage import data, exposure\n",
    "\n",
    "from skimage.exposure import histogram\n",
    "from matplotlib.pyplot import bar\n",
    "import os\n",
    "import nbimporter\n",
    "from hog import *\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 7843\n",
      "Image dimensions: 32 x 32\n",
      "Number of unique target names: 7843\n"
     ]
    }
   ],
   "source": [
    "# Window size\n",
    "WINDOW_SIZE = 32\n",
    "# Load the LFW dataset\n",
    "lfw_dataset = fetch_lfw_people(min_faces_per_person=2)\n",
    "\n",
    "# Access the data (original images)\n",
    "original_images = lfw_dataset.images\n",
    "\n",
    "# Resize the images to 32x32 pixels\n",
    "resized_face_images = [resize(image, (WINDOW_SIZE, WINDOW_SIZE), mode='reflect') for image in original_images]\n",
    "\n",
    "# Convert the resized images to numpy array\n",
    "resized_face_images = np.array(resized_face_images)\n",
    "\n",
    "# Print the new size of the images\n",
    "n_samples, h, w = resized_face_images.shape\n",
    "# Print some information about the dataset\n",
    "print(\"Number of samples:\", n_samples)\n",
    "print(\"Image dimensions:\", h, \"x\", w)\n",
    "print(\"Number of unique target names:\", len(resized_face_images))\n",
    "# Save the resized images to file\n",
    "np.savez_compressed('Train Images/Head/resized_face_images.npz', resized_face_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 7843\n",
      "Image dimensions: 32 x 32\n",
      "Number of unique target names: 7843\n"
     ]
    }
   ],
   "source": [
    "# Load the resized images from file\n",
    "resized_face_images = np.load('Train Images/Head/resized_face_images.npz')['arr_0']\n",
    "# Print the new size of the images\n",
    "n_samples, h, w = resized_face_images.shape\n",
    "# Print some information about the dataset\n",
    "print(\"Number of samples:\", n_samples)\n",
    "print(\"Image dimensions:\", h, \"x\", w)\n",
    "print(\"Number of unique target names:\", len(resized_face_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open folder with images\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = io.imread(os.path.join(folder,filename))\n",
    "        # check if image is already gray\n",
    "        if len(img.shape) != 2:\n",
    "            img = rgb2gray(img)\n",
    "        # resize image to 32x32\n",
    "        img = resize(img, (WINDOW_SIZE, WINDOW_SIZE), mode='reflect')\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative images: 3030\n"
     ]
    }
   ],
   "source": [
    "# load negative images\n",
    "negative_images = load_images_from_folder(\"Negative Images\")\n",
    "print(\"Number of negative images:\", len(negative_images))\n",
    "# Save the negative images to file\n",
    "np.savez_compressed('Negative.npz', negative_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative images: 3030\n"
     ]
    }
   ],
   "source": [
    "# Load the negative images from file\n",
    "negative_images = np.load('Negative.npz')['arr_0']\n",
    "print(\"Number of negative images:\", len(negative_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hand images: 11076\n"
     ]
    }
   ],
   "source": [
    "# Load hand images\n",
    "hand_images = load_images_from_folder(\"Train Images/Hand/Hands/Hands\")\n",
    "print(\"Number of hand images:\", len(hand_images))\n",
    "# Save the hand images to file\n",
    "np.savez_compressed('Train Images/Hand/Hands/Hands.npz', hand_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hand images: 11076\n",
      "Image dimensions: (32, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the hand images from file\n",
    "hand_images = np.load('Train Images/Hand/Hands/Hands.npz')['arr_0']\n",
    "print(\"Number of hand images:\", len(hand_images))\n",
    "print(\"Image dimensions:\", hand_images[0].shape)\n",
    "plt.imshow(hand_images[9], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face And Hands Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features from positive images and negative images\n",
    "face_features_array = []\n",
    "hand_features_array = []\n",
    "hand_labels_array = []\n",
    "face_labels_array = []\n",
    "for i in range(0, 5000):\n",
    "    img = resized_face_images[i]\n",
    "    fd = get_features_hog(img, orientations=9, pixels_per_cell=(3, 3), cells_per_block=(2, 2))\n",
    "    face_features_array.append(fd)\n",
    "    face_labels_array.append(1)\n",
    "for i in range(0, 5000):\n",
    "    img = hand_images[i]\n",
    "    fd = get_features_hog(img, orientations=9, pixels_per_cell=(3, 3), cells_per_block=(2, 2))\n",
    "    hand_features_array.append(fd)\n",
    "    hand_labels_array.append(1)\n",
    "for i in range(0, 3030):\n",
    "    img = negative_images[i]\n",
    "    fd = get_features_hog(img, orientations=9, pixels_per_cell=(3, 3), cells_per_block=(2, 2))\n",
    "    face_features_array.append(fd)\n",
    "    face_labels_array.append(0)\n",
    "    hand_features_array.append(fd)\n",
    "    hand_labels_array.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 2916\n",
      "Number of features: 2916\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of features:\", len(face_features_array[0]))\n",
    "print(\"Number of features:\", len(hand_features_array[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['face_model.sav']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_recognizer = SVC(C=10000, gamma=0.000001, kernel='rbf', probability=True)\n",
    "# Split the dataset into training and testing set\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(face_features_array, face_labels_array, test_size=0.2, random_state=0)\n",
    "# Train the model\n",
    "face_recognizer.fit(features_train, labels_train)\n",
    "# Save the model to disk\n",
    "joblib.dump(face_recognizer, 'face_model.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence: [[9.99999498e-01 5.01909137e-07]]\n",
      "Predicted label: [0]\n",
      "Predicted label: 0\n",
      "Accuracy: 0.9806973848069739\n"
     ]
    }
   ],
   "source": [
    "# Load the model from disk\n",
    "face_recognizer = joblib.load('face_model.sav')\n",
    "# get confidence of single image\n",
    "confidence = face_recognizer.predict_proba(features_test[0].reshape(1, -1))\n",
    "print(\"Confidence:\", confidence)\n",
    "print(\"Predicted label:\", confidence.argmax(axis=1))\n",
    "print(\"Predicted label:\", labels_test[0])\n",
    "# Get accuracy\n",
    "accuracy = face_recognizer.score(features_test, labels_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hand_model.sav']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hand_recognizer = SVC(C=10000, gamma=0.000001, kernel='rbf', probability=True)\n",
    "# Split the dataset into training and testing set\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(hand_features_array, hand_labels_array, test_size=0.2, random_state=0)\n",
    "# Train the model\n",
    "hand_recognizer.fit(features_train, labels_train)\n",
    "# Save the model to disk\n",
    "joblib.dump(hand_recognizer, 'hand_model.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence: [[9.99988129e-01 1.18710684e-05]]\n",
      "Predicted label: [0]\n",
      "Predicted label: 0\n",
      "Accuracy: 0.9993773349937733\n"
     ]
    }
   ],
   "source": [
    "# Load the model from disk\n",
    "hand_recognizer = joblib.load('hand_model.sav')\n",
    "# get confidence of single image\n",
    "confidence = hand_recognizer.predict_proba(features_test[0].reshape(1, -1))\n",
    "print(\"Confidence:\", confidence)\n",
    "print(\"Predicted label:\", confidence.argmax(axis=1))\n",
    "print(\"Predicted label:\", labels_test[0])\n",
    "# Get accuracy\n",
    "accuracy = hand_recognizer.score(features_test, labels_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Face model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_test_images(inputPath = \"Test Images\", outputPath = \"Output\"):\n",
    "    \n",
    "    for filename in os.listdir(inputPath):\n",
    "        img = io.imread(os.path.join(inputPath,filename))\n",
    "\n",
    "        # check if image is already gray\n",
    "        if len(img.shape) != 2:\n",
    "            img = rgb2gray(img)\n",
    "        \n",
    "        # resize image to 256x256\n",
    "        img = resize(img, (256, 256), mode='reflect')\n",
    "        io.imsave(os.path.join(outputPath,filename), (img * 255).astype(np.uint8))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_voting_mateix_face(img):\n",
    "    # take upper corner of image\n",
    "    img = img[0:256 // 4, 0:256]\n",
    "    # get the size of image\n",
    "    height, width = img.shape\n",
    "    \n",
    "    # get x and y increment\n",
    "    x_increment = height // 4\n",
    "    y_increment = width // 8\n",
    "    \n",
    "    # get the voting matrix\n",
    "    voting_matrix = np.zeros((height // WINDOW_SIZE, width // WINDOW_SIZE))\n",
    "    \n",
    "    # print some information\n",
    "    # print(\"Image size:\", img.shape)\n",
    "    # print(\"x increment:\", x_increment, \"y increment:\", y_increment)\n",
    "    # print(\"Voting matrix size:\", voting_matrix.shape)\n",
    "    \n",
    "    for y in range(0, height - WINDOW_SIZE, y_increment):\n",
    "        if y > height / 4:\n",
    "            break\n",
    "        for x in range(0, width - WINDOW_SIZE, x_increment):\n",
    "            # get the image patch\n",
    "            img_patch = img[y:y+WINDOW_SIZE, x:x+WINDOW_SIZE]\n",
    "            # get the HOG features\n",
    "            fd = get_features_hog(img_patch, orientations=9, pixels_per_cell=(3, 3), cells_per_block=(2, 2))\n",
    "            # get the confidence\n",
    "            confidence = face_recognizer.predict_proba(fd.reshape(1, -1))\n",
    "            # get the confidence of face\n",
    "            face_confidence = confidence[0][1]\n",
    "            # add the confidence to voting matrix\n",
    "            voting_matrix[y // WINDOW_SIZE, x // WINDOW_SIZE] = face_confidence\n",
    "            if x % WINDOW_SIZE != 0:\n",
    "                voting_matrix[y // WINDOW_SIZE, math.ceil(x / WINDOW_SIZE)] += face_confidence * (x % WINDOW_SIZE) / WINDOW_SIZE\n",
    "            if y % WINDOW_SIZE != 0:\n",
    "                voting_matrix[math.ceil(y / WINDOW_SIZE), x // WINDOW_SIZE] += face_confidence * (y % WINDOW_SIZE) / WINDOW_SIZE\n",
    "            if x % WINDOW_SIZE != 0 and y % WINDOW_SIZE != 0:\n",
    "                voting_matrix[math.ceil(y / WINDOW_SIZE), math.ceil(x / WINDOW_SIZE)] += face_confidence * (x % WINDOW_SIZE) * (y % WINDOW_SIZE) / (WINDOW_SIZE * WINDOW_SIZE)\n",
    "    return voting_matrix\n",
    "\n",
    "def get_voting_mateix_hand(img):\n",
    "    # take lower corner of image\n",
    "    img = img[256 // 4 * 2:256, 0:256]\n",
    "    # get the size of image\n",
    "    height, width = img.shape\n",
    "    \n",
    "    # get x and y increment\n",
    "    x_increment = height // 4\n",
    "    y_increment = width // 8\n",
    "    \n",
    "    # get the voting matrix\n",
    "    voting_matrix = np.zeros((height // WINDOW_SIZE, width // WINDOW_SIZE))\n",
    "    \n",
    "    # print some information\n",
    "    # print(\"Image size:\", img.shape)\n",
    "    # print(\"x increment:\", x_increment, \"y increment:\", y_increment)\n",
    "    # print(\"Voting matrix size:\", voting_matrix.shape)\n",
    "    \n",
    "    for y in range(0, height - WINDOW_SIZE, y_increment):\n",
    "        if y > height / 4:\n",
    "            break\n",
    "        for x in range(0, width - WINDOW_SIZE, x_increment):\n",
    "            # get the image patch\n",
    "            img_patch = img[y:y+WINDOW_SIZE, x:x+WINDOW_SIZE]\n",
    "            # get the HOG features\n",
    "            fd = get_features_hog(img_patch, orientations=9, pixels_per_cell=(3, 3), cells_per_block=(2, 2))\n",
    "            # get the confidence\n",
    "            confidence = hand_recognizer.predict_proba(fd.reshape(1, -1))\n",
    "            # get the confidence of face\n",
    "            face_confidence = confidence[0][1]\n",
    "            # add the confidence to voting matrix\n",
    "            voting_matrix[y // WINDOW_SIZE, x // WINDOW_SIZE] = face_confidence\n",
    "            if x % WINDOW_SIZE != 0:\n",
    "                voting_matrix[y // WINDOW_SIZE, math.ceil(x / WINDOW_SIZE)] += face_confidence * (x % WINDOW_SIZE) / WINDOW_SIZE\n",
    "            if y % WINDOW_SIZE != 0:\n",
    "                voting_matrix[math.ceil(y / WINDOW_SIZE), x // WINDOW_SIZE] += face_confidence * (y % WINDOW_SIZE) / WINDOW_SIZE\n",
    "            if x % WINDOW_SIZE != 0 and y % WINDOW_SIZE != 0:\n",
    "                voting_matrix[math.ceil(y / WINDOW_SIZE), math.ceil(x / WINDOW_SIZE)] += face_confidence * (x % WINDOW_SIZE) * (y % WINDOW_SIZE) / (WINDOW_SIZE * WINDOW_SIZE)\n",
    "    return voting_matrix\n",
    "\n",
    "def put_dots_on_image(img, voting_matrix, start_of_image_part = 0, mode = \"face\"):\n",
    "    if mode == \"face\":\n",
    "        start_of_image_part = 0\n",
    "    elif mode == \"hand\":\n",
    "        start_of_image_part = 256 // 4 * 2\n",
    "    # get the highest two values from voting matrix\n",
    "    max_value = np.max(voting_matrix)\n",
    "    max_value_index = np.where(voting_matrix == max_value)\n",
    "    voting_matrix[max_value_index] = 0\n",
    "    second_max_value = np.max(voting_matrix)\n",
    "    second_max_value_index = np.where(voting_matrix == second_max_value)\n",
    "    # get the coordinates of the highest two values\n",
    "    # get the coordinates of the dots\n",
    "    # x = col * window_width + window_width / 2\n",
    "    # y = row * window_height + start_of_image_part + window_height / 2\n",
    "    x1 = max_value_index[1][0] * WINDOW_SIZE + WINDOW_SIZE / 2\n",
    "    y1 = max_value_index[0][0] * WINDOW_SIZE + start_of_image_part + WINDOW_SIZE / 2\n",
    "    x2 = second_max_value_index[1][0] * WINDOW_SIZE + WINDOW_SIZE / 2\n",
    "    y2 = second_max_value_index[0][0] * WINDOW_SIZE + start_of_image_part + WINDOW_SIZE / 2\n",
    "    # draw red dots on image\n",
    "    cv.circle(img, (int(x1) , int(y1)), 5, (1.0, 0, 0), -1)\n",
    "    cv.circle(img, (int(x2), int(y2)), 5, (1.0, 0, 0), -1)\n",
    "    # if x1 < x2:\n",
    "    #     xr, yr = x1, y1\n",
    "    # else:\n",
    "    #     xr, yr = x2, y2\n",
    "    #cv.rectangle(img, (int(xr), int(yr)), (int(xr) + 2 * WINDOW_SIZE, int(yr) + 2 * WINDOW_SIZE), (0, 1, 0), 2)\n",
    "    #cv.rectangle(img, (int(x1), int(y1)), (int(x1) + 2 * WINDOW_SIZE, int(y1) + 2 * WINDOW_SIZE), (0, 1, 0), 2)\n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "resize_test_images()\n",
    "for filename in os.listdir(\"Output\"):\n",
    "    img = io.imread(os.path.join(\"Output\",filename))\n",
    "    heat_matrix = get_voting_mateix_face(img)\n",
    "    img = io.imread(os.path.join(\"Test Images\",filename))\n",
    "    img = resize(img, (256, 256), mode='reflect')\n",
    "    result = put_dots_on_image(img, heat_matrix)\n",
    "    #plt.imshow(result)\n",
    "    #plt.show()\n",
    "    # remove image from folder\n",
    "    os.remove(os.path.join(\"Output\",filename))\n",
    "    io.imsave(os.path.join(\"Output\",filename), (result * 255).astype(np.uint8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1310c6520792fcb7b0d25c1401245ed3fb6ffb6ace4a4c81d480b3badb3c3aa5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
